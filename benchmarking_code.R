benchmarking = function(df ,
                         no_of_factor = 3,
                         minimum_cor2_percentile = 0.5,
                         minimum_adjr2 = 0.8,
                         irrelevent_variables = c('iTraxx_5yr_senior'),
                         transformations_list = list('QoQ_D' = qoq,'QoQ_P' = qoq_p,'L1' = L1 ),
                         non_transformed_x = c('D1','D2'),
                         dependent_var = 'street_fees',
                         parallel_computing = TRUE){
  
  # Developed by Suraj Kumar with inspiration and inputs from Arghya Ghosh
  
  # df = input data frame contains MEFs(Xs), Non_transmfored Xs (such as Dummy Variable (Ds) or AR Terms) and dependent variable(Y)
  
  # no_of_factor = Number of MEFs to consider
  
  # minimum_cor2_percentile = its threshold which filter out MEFs with all possible transformation.
  #       for example: if minimum_cor2_percentile  = 0.5, then 50% of Xs with transformation are filtered out
  #                     which have lowest corelation with dependent variable
  
  # minimum_adj2 = Its threshold limit of adjusted R2 of models generated by benchmarking function. 
  #       for example: if minimum_adj2 = 0.5, then the function would generate only those models
  #                     which have adj2 >= 0.5.
  
  # irrelevent_variables = It filter out those variables which we don't want in tht model
  
  # transformations_list  = It is list of functions to be used as transformation on Xs. 
  
  # non_transformed_x = It specify which of the Xs in X dataframe is not to be transformed but used as it is in model. 
  
  # dependent_var = Y
  
  # parallel_computing = It specify whether the calculation for best model search is done parallel or in sequential way   
  
  
  #Removing irrelevent variables
  df = df[,!colnames(df) %in% irrelevent_variables]
  
  #Extracting Non transfomed Xs in a seperate dataset so that transformations are not applied to it
  non_transformed_df = subset(df, select = non_transformed_x)
  
  #Dropping Non-Transfomed Xs from df, Non-Transformed Xs will be added later
  df[,non_transformed_x] = NULL
  
  # Applying Transformations
  print('Conserding following Transformations')
  print(names(transformations_list))
  
  # Initating emply list
  transformed_df_list = list()
  for(i in 1:length(transformations_list)){
    # Creatiing a temporary df formed after applying a function from transformation list on the df
    temp_df = data.frame( lapply(df[,!colnames(df) %in% dependent_var],
                                 transformations_list[[i]] ) )
    # Assiging colnames to temporary df
    colnames(temp_df) = paste(  names(transformations_list)[i],
                                colnames(df[,!colnames(df) %in% dependent_var])  )
    # Storing the temporary df on the transformed_df_list
    transformed_df_list[[i]] = temp_df
  }
  
  # Combining df and Transformed Df
  df = dplyr::bind_cols(df,transformed_df_list)
  
  
  # Ditching nonsense values
  ditch <- function(x) { ifelse(is.infinite(x) | is.nan(x), NA, x) }
  df =  data.frame(lapply(df,ditch))
  
  # Creating a correlation matrix with dependent variable
  cor_mat = cor(x = df,y = df[,dependent_var],use = 'pairwise.complete.obs')
  cor_df = setNames(data.frame(cor_mat),'correlation')
  
  # Calculating R2 value of dependent variable with MEFS
  cor_df$cor2 = (cor_df$correlation)^2
  
  # Filtering out low r2 values 
  low_cor2_value = quantile(cor_df$cor2,minimum_cor2_percentile)
  cor_df = cor_df[cor_df$cor2 >= low_cor2_value,]
  
  # Subsetting_df by removing variables which have low correlation with dependent variable
  df = subset(df, select = rownames(cor_df))
  print('The variable choosen after r2 filtering are')
  print(colnames(df))
  
  #Findig out How many models to test
  print( paste0( 'No of linear regressions to Test are ',
                 choose(dim(df[,!colnames(df) %in% dependent_var])[2],no_of_factor) ) )
  
  # Making combinations of all possible Xs from df (Non-Transformed Xs have already been revmoved )after removing y
  
  # It output is like a dataframe where number of columns are number of combinations considered and number of rows
  # is equal to number of factors considered in the model
  # For example in a 3 factor model, a column of combinations dataframe represent a combination with 3 rows each 
  # representing the variable of the combination such as GDP, unemployment or inflation
  combinations = data.frame(combn(x = colnames(df[,!colnames(df) %in% dependent_var]),
                                  no_of_factor))
  
  
  # Initiating a Emply list, It will be used later to store variable and then would be used to make a dataframe
  combinations_list = list()
  
  # Following for loop is used to store each column of combinations as vector of character in combinations_list 
  for(i in 1:dim(combinations)[2]){
    combinations_list[[i]] = as.character(combinations[,i])
  }
  
  
  # It create a dataframe with colname "Vars" whose each element is list which contains some combinatio of variables considered from df
  combinations_df = data.frame('Vars' = I(combinations_list))
  
  
  
  #Adding Non-Transformed Xs back to df
  df = cbind(df,non_transformed_df)
  
  # Colname Function to generate appropriate colnames for Xs
  col_names_fun = function(no_of_factor,non_transformed_x){
    s = rep(NA,no_of_factor)
    s[1] = 'Intercept'
    for(i in 2:(1+no_of_factor)){
      s[i] = paste0('V',i-1)
    }
    return(c(s,non_transformed_x))
  }
  
  
  #Running instance of col_names_fun
  col_names = col_names_fun(no_of_factor,non_transformed_x)
  
  # Main Regression Function insider this benchmarking function
  model_regression_func = function(varlist){
    
    # unlisting the variables into a vector
    var_list = unlist(varlist)
    
    # Selecting only relevent variables from df
    model_df = subset(df, select= c(dependent_var,var_list,non_transformed_x))
    
    # Running regression 
    model = lm(as.formula(paste0(dependent_var,'~ .')), 
               data = model_df)
    
    # Summary of model
    summary_model = summary(model)
    
    # Adjusted R2
    adjr2 = summary_model$adj.r.squared
    
    # Rejecting a model if the adjuster r2 of it is below a threshold
    if(adjr2 <= minimum_adjr2){
      return(NULL)
    }
    
    # Rejecting a model if one of the coefficient of the model is NA on account of perfect multicollinearity or
    #  high correlation amount varialbes
    if(any(is.na(coef(model)))){
      return(NULL)
    }
    
    
    # Generating a dataframe with coefficient estimates and their p values
    summary_df = as.data.frame(summary_model$coefficients)
    
    
    # Extracting coefficients
    coeff_df = as.data.frame(t(summary_df$Estimate))
    
    # Extracting pvalues
    pvalues_df = as.data.frame(t(summary_df$`Pr(>|t|)`))
    
    
    # Replacing colnames of coeff_df and pvalues_df with appropriate colnames from col_names_fun above
    coeff_df = setNames(coeff_df,paste0('coeff_',col_names))
    pvalues_df = setNames(pvalues_df,paste0('pvalue_',col_names))
    
    # Storing DOF
    dof = summary_model$df[2]
    
    # Creating a dataframe of variables which have been considered in the regression
    var_list_df = as.data.frame(matrix(data = var_list,nrow = 1))
    
    # Return a combined dataframe of variable, coefficinets, pvalues, adjusted r2 and degree of freedom
    return(data.frame(var_list_df,coeff_df,pvalues_df,'adjr2' = adjr2,'dof' = dof))
  }
  
  # if computing is to be done in a parallel way
  if(parallel_computing){
    #library(parallel)
    # Returns number of physical cores in the CPU of the computer and then make that many clusters(workers)
    cl = makeCluster(detectCores()) #Initiating clusters 
    
    #  Applying the model_regression_func in for loop manner to each element of combinations_df$Vars
    # parLapply is the parallel version of lapply
    models_df = dplyr::bind_rows(parLapply(cl,combinations_df$Vars,model_regression_func)) 
    stopCluster(cl) # Stopping clusters
  } else{
    
    # It runs when computing is done in serial way
    # Applying the model_regression_func in for loop manner to each element of combinations_df$Vars
    models_df = dplyr::bind_rows(lapply(combinations_df$Vars,model_regression_func))
  }
  
  
  # It might happen that there is no model in the combinaiton considered which has higher adjuster r2 then the threshold specified
  if(nrow(models_df)== 0){
    print('The no regression combination has adjusted r2 higher then the specified')
    return()
  }
  # Returns the model in the decreasing order of adjusted r2
  return(models_df[order(-models_df$adjr2),])
  
}